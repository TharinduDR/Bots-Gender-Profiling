{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.callbacks import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get reproducable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "seed(726)\n",
    "set_random_seed(726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (123814, 5)\n",
      "Test shape :  (30954, 5)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_gender_en.tsv\", sep='\\t')\n",
    "test = pd.read_csv(\"data/test_gender_en.tsv\", sep='\\t')\n",
    "\n",
    "print(\"Train shape : \", train.shape)\n",
    "print(\"Test shape : \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114531</td>\n",
       "      <td>bdda1c2944c5f9872361ab7b5c5320cb</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>@philford @travelling_wolf I could tell you th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46421</td>\n",
       "      <td>5776d9eb6c5d1e3de13669717394aac4</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>love the water colour https://t.co/7u88fwNs8X'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9345</td>\n",
       "      <td>1d50b53bef7c27c8fc0042707c0a4f94</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>DAY 313: DO YOU KNOW HOW MUCH IVORY COMES THRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28823</td>\n",
       "      <td>3af4cc9b03a55c55028cdf06bdd50701</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "      <td>@Aoife_Dooley Can you leave stuff in your Nana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4358</td>\n",
       "      <td>1575e6912b5ded0eea725df87315174a</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>“@BBCSport: Crystal Palace in talks to re-sign...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  human  gender  \\\n",
       "0      114531  bdda1c2944c5f9872361ab7b5c5320cb  human    male   \n",
       "1       46421  5776d9eb6c5d1e3de13669717394aac4  human    male   \n",
       "2        9345  1d50b53bef7c27c8fc0042707c0a4f94  human    male   \n",
       "3       28823  3af4cc9b03a55c55028cdf06bdd50701  human  female   \n",
       "4        4358  1575e6912b5ded0eea725df87315174a  human    male   \n",
       "\n",
       "                                               tweet  \n",
       "0  @philford @travelling_wolf I could tell you th...  \n",
       "1     love the water colour https://t.co/7u88fwNs8X'  \n",
       "2  DAY 313: DO YOU KNOW HOW MUCH IVORY COMES THRO...  \n",
       "3  @Aoife_Dooley Can you leave stuff in your Nana...  \n",
       "4  “@BBCSport: Crystal Palace in talks to re-sign...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125543</td>\n",
       "      <td>d0296beb6a2a53abf04fb93a4c3c6c5d</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "      <td>After the Wrap: The Post-Shooting Life of Sixt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127241</td>\n",
       "      <td>d2dcf7042718b24b2c3c86fa39c85ddb</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>@basic_john_ Breath Of The Wild is so pretty i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119945</td>\n",
       "      <td>c6e5e9c92fb338dc0e029d9ea22a4358</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>Sooo... I spent two hours playing minesweeper'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82175</td>\n",
       "      <td>8d4fe42db5d78e1efd87b61ccf8128c9</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>@RWBranca Has Brady considering submitting all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62776</td>\n",
       "      <td>72c0d735d98a61bbb28c2292f28ed91e</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>RT @JamTarts: Congratulations to Derek Fraser ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  human  gender  \\\n",
       "0      125543  d0296beb6a2a53abf04fb93a4c3c6c5d  human  female   \n",
       "1      127241  d2dcf7042718b24b2c3c86fa39c85ddb  human    male   \n",
       "2      119945  c6e5e9c92fb338dc0e029d9ea22a4358  human    male   \n",
       "3       82175  8d4fe42db5d78e1efd87b61ccf8128c9  human    male   \n",
       "4       62776  72c0d735d98a61bbb28c2292f28ed91e  human    male   \n",
       "\n",
       "                                               tweet  \n",
       "0  After the Wrap: The Post-Shooting Life of Sixt...  \n",
       "1  @basic_john_ Breath Of The Wild is so pretty i...  \n",
       "2     Sooo... I spent two hours playing minesweeper'  \n",
       "3  @RWBranca Has Brady considering submitting all...  \n",
       "4  RT @JamTarts: Congratulations to Derek Fraser ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing case of the tweets to lower case, since the embedding model only has lower case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tweet\"] = train[\"tweet\"].str.lower()\n",
    "test[\"tweet\"] = test[\"tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the puncutation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda x: clean_text(x))\n",
    "test[\"tweet\"] = test[\"tweet\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize word distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEXCAYAAACtTzM+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmYFNW9//H3dwYYVpHNXAUMGAEVQVBQQRNIUBSvRo0L5rpA9BEScSFXH6+4xy3xxlxNjHrhRsRgjCAERS8J/EBxCSpLROMSAiqR4WoERGVnZvj+/qhqphlmpmumq6eZrs/refrprlOnqr41rf3lnFN1ytwdERGRonwHICIi+wYlBBERAZQQREQkpIQgIiKAEoKIiISUEEREBFBCEImNma02s5PycNxuZuZm1qShjy2FRQlBGp18/PCa2e1m9kRDHrMm+Uo8UviUEEREBFBCkEbGzKYCBwPPmdlmM7vezB43s2vD9Z3D7pNx4fI3zOxzMysKl083s+Vm9oWZLTKzvmn7PsjMZprZOjP7yMyuDstPBW4ERobHfCtCnEVmdoOZfWBmG8xsupm1D9elunhGmdnHZrbezG5K27ZFeE4bzez98BxLazr/tMNeWN3+RKJSQpBGxd0vBj4GznD31u7+n8BLwNCwyhDgQ+BbacuvuPsuM+sPTAbGAh2AicBsMysJE8ZzwFtAZ2AYMN7MTnH3PwH3ANPCYx4VIdSrgLPC4x8EbAQeqlLnRKBXeKxbzezwsPw2oBtwCHAycFGG88+0P5FIlBCkELwEnBj+qH8L+E/ghHDdkHA9wBhgoru/4e4V7v44sAM4HhgIdHL3O9x9p7t/CPwPcEE9Y/ohcJO7l7r7DuB24NwqA78/cfdt7v4WQSJKJZrzgXvcfaO7lwK/injMmvYnEomuSpBGz90/MLMtQD/gm8CdwGVm1osgIaR+UL8OjDKzq9I2b0bwL/gK4CAz+yJtXTHwSj3D+jowy8x2pZVVAF9LW/407fNWoHX4+SBgTdq69M+1qWl/IpEoIUhjVN0UvS8B5wLN3H2tmb0EjALaAcvDOmuAu9397qobm9kg4CN371GHY9ZmDXCpu/+5mmN1y7DtJ0AX4L1wuWuWsYhEoi4jaYz+SdC/nu4l4Erg5XB5Ybj8qrtXhGX/A/zQzI6zQCsz+1czawMsBjaZ2X+Eg7rFZnakmQ1MO2a31OB0BP8N3G1mXwcws05mdmbEbacDE8ysnZl1Ds8jXXXnL5I1JQRpjH4K3BxeKXRdWPYS0IbKhPAq0DJtGXdfClwO/JpgkHcVMDpcVwGcTtDt9BGwHvgN0Dbc/OnwfYOZ/SVCjL8EZgPzzGwT8DpwXMTzuwMoDeOYD8wgGOtIqe78RbJmekCOyL7NzH4EXODuQ/IdixQ2tRBE9jFmdqCZnRDey9ALuBaYle+4pPBpUFlk39OM4B6J7sAXwFPAw3mNSBJBXUYiIgKoy0hEREKNqsuoY8eO3q1bt3yHsduKFSsA6NWrV54jERGp2bJly9a7e6dM9RpVQujWrRtLly7Ndxi7DR06FICFCxfmNQ4RkdqY2T+i1FOXkYiIAI2shbCvufnmm/MdgohIbJQQsnDSSXpolYgUDiWELCxfHsyZ1q9fvzxHIlKYysrKKC0tZfv27fkOpVFo3rw5Xbp0oWnTpvXaXgkhC+PHjwc0qCySK6WlpbRp04Zu3bphZvkOZ5/m7mzYsIHS0lK6d+9er31oUFlE9lnbt2+nQ4cOSgYRmBkdOnTIqjWlhCAi+zQlg+iy/VspIYiICKCEsJfFi2HIEPhV1KfYiohkYeHChZx++un5DgPQoPJuu3bBj38MDz4I7nDAAXD11bVvc8899zRMcCIiDUAthNCLLwatgksvhR49oKws8zaDBw9m8ODBuQ9ORPJi9erVHHbYYYwePZqePXty4YUXMn/+fE444QR69OjB4sWLAVi8eDGDBg2if//+DB48ePc8Z/fffz+XXnopAH/961858sgj2bp1a43H27JlC5deeinHHnss/fv359lnnwVgypQpfO973+PUU0+lR48eXH/99Tk5X7UQQv8IZ/q46SZ46y3YuTPzNosWLQJQUhBpIKn5w9Kdf/75XHHFFWzdupXTTjttr/WjR49m9OjRrF+/nnPPPXePdVEuGV+1ahVPP/00kydPZuDAgTz55JO8+uqrzJ49m3vuuYdnnnmGww47jFdeeYUmTZowf/58brzxRmbOnMk111zD0KFDmTVrFnfffTcTJ06kZcuWNR7r7rvv5jvf+Q6TJ0/miy++4Nhjj919A+zy5ct58803KSkpoVevXlx11VV07do1Y/x1oYQQWrs2eD/oIGjaNFoL4cYbbwR0H4JIIevevTt9+vQBoHfv3gwbNgwzo0+fPqxevRqAL7/8klGjRrFy5UrMjLLwB6SoqIgpU6bQt29fxo4dywknnFDrsebNm8fs2bO57777gOCy248//hiAYcOG0bZt8IjvI444gn/84x9KCLlSWgqdOkFJSfSEICINq7Z/fLVs2bLW9R07dqzXP95KSkp2fy4qKtq9XFRURHl5OQC33HIL3/72t5k1axarV6/eoyWzcuVKWrduzf/93/9lPJa7M3PmzL2m1H/jjTf2iKO4uHj3seOkMYRQaSl06RJ8btYsWpeRiAgELYTOnTsDQX9/evnVV1/Nyy+/zIYNG5gxY0at+znllFN48MEHST3J8s0338xZzNVRQgilJwS1EESkLq6//nomTJhA//799/iX+49//GPGjRtHz549efTRR7nhhhv47LPPatzPLbfcQllZGX379qV3797ccsstDRH+bo3qmcoDBgzwXD0gp2NHOP98ePhhOOss+OijYHC5NnpAjkhuvf/++xx++OH5DqNRqe5vZmbL3H1Apm01hgBs2wYbNkDY4ovcQnjggQdyG5iISANSQqDyCqO6jiFo2msRKSQaQ2DvhBC1hTB//nzmz5+fu8BERBqQWggEA8pQ9xbCXXfdBejJaSJSGNRCoDIh1HUMQUSkkCghECSEFi3gySdh0iRYsQK2bAk+i4gkhbqMCMYQ2rWrXC4uhoqK/MUjItWL+x9pY8bUrf7tt99O69atue6667I6buvWrdm8eXNW+8gFtRAIWgj771+5rIQgIkmkhECQEKq2EHbtCl61mThxIhMnTsxtcCKSV3fffTc9e/bkxBNP3D2tNQSzjx5//PH07duXs88+m40bNwLB7KgnnXQSRx11FEcffTQffPBBrfv/+c9/zsCBA+nbty+33XYbEEy7ffjhh3P55ZfTu3dvhg8fzrZt23J3kqHEJ4SyMvj0071bCJC5ldCrV6+9JqESkcKxbNkynnrqKZYvX86cOXNYsmTJ7nWXXHIJ9957L2+//TZ9+vThJz/5CQAXXngh48aN46233mLRokUceOCBNe5/3rx5rFy5ksWLF7N8+XKWLVvGyy+/DAST4o0bN453332X/fffn5kzZ+b2ZNEYAp9+GjwhLb2F0CT8q2RKCM899xwAZ5xxRo6iE5F8euWVVzj77LN3P8Pgu9/9LhBMWvfFF18wZMgQAEaNGsV5553Hpk2bWLt2LWeffTYAzZs3r3X/8+bNY968efTv3x+AzZs3s3LlSg4++GC6d+++++bXY445ZvdU27mU+ISQuuS0apcRZE4Iv/jFLwAlBBGpH3dnwoQJjB07do/y1atX7zXdtbqMGkAqIaR3GaVaCDmYblxEGpFvfetbPPPMM2zbto1Nmzbt7hVo27Yt7dq145VXXgFg6tSpDBkyhDZt2tClSxeeeeYZAHbs2FHrIzNPOeUUJk+evPuKo7Vr19Y6G2quJb6FkJq2oj4tBBFpWHW9TDRbRx99NCNHjuSoo47igAMOYODAgbvXPf744/zwhz9k69atHHLIITz22GNAkBzGjh3LrbfeStOmTXn66ac55JBDqt3/8OHDef/99xk0aBAQXI76xBNPUJz6EWpgiU8IqZvS0h9zqoQgIik33XQTN910017l/fr14/XXX9+rvEePHrzwwgu17jP9HoRrrrmGa665Zq8677zzzu7P2d73EFXiu4w+/RT+5V/ArLJMCUFEkijxLYQdO4IWQrqoVxlNnTo1N0GJiORBpBaCmZ1qZivMbJWZ3VDN+hIzmxauf8PMuoXlJ5vZMjP7a/j+nbRtjgnLV5nZr8zS/43ecHbuDGY3TZdqIWQaVO7atStdu3bNTWAiAkBjeqpjvmX7t8qYEMysGHgIGAEcAXzfzI6oUu0yYKO7HwrcD9wblq8HznD3PsAoIP2f1I8AlwM9wtepWZxHvZWV1ZwQMrUQpk2bxrRp03ITmIjQvHlzNmzYoKQQgbuzYcOGjPc+1CZKl9GxwCp3/xDAzJ4CzgTeS6tzJnB7+HkG8GszM3d/M63Ou0ALMysB2gP7ufvr4T5/C5wF/LHeZ1JPO3cG012ni9pCeOSRRwAYOXJkDiITkS5dulBaWsq6devyHUqj0Lx5c7qkHuxSD1ESQmdgTdpyKXBcTXXcvdzMvgQ6ELQQUs4B/uLuO8ysc7if9H12ru7gZjYGGANw8MEHRwi3bmrrMtKgskh+NW3alO7du+c7jMRokKuMzKw3QTfS2Ex1q3L3Se4+wN0HdOrUKfbYqksIUQeVRUQKSZSEsBZIHzntEpZVW8fMmgBtgQ3hchdgFnCJu3+QVj+9XVPdPhtEWVnNXUZKCCKSJFESwhKgh5l1N7NmwAXA7Cp1ZhMMGgOcC7zg7m5m+wP/C9zg7n9OVXb3T4CvzOz48OqiS4BnszyXeqmthaCpK0QkSTKOIYRjAlcCc4FiYLK7v2tmdwBL3X028Cgw1cxWAZ8TJA2AK4FDgVvN7NawbLi7fwZcAUwBWhAMJjf4gDJkN4YwY8aM3AQlIpIHkW5Mc/c5wJwqZbemfd4OnFfNdncBd9Wwz6XAkXUJNheyuey0Y8eOuQlKRCQPEj91RW2XnWZKCFOmTGHKlCk5iUtEpKEpIWTRZaSEICKFRAlBg8oiIoASgi47FREJJT4hZDO5nYhIIUl0QnAPfvQ1dYWISMKfh1BWFrxXTQhFRcErU0KYM2dO7RVERBqRRCeEnTuD96pjCBC0EjIlhJbpz90UEWnkEt1llEoIVVsIECSETGMIDz/8MA8//HD8gYmI5IESAjUnhEwthOnTpzN9+vT4AxMRyYNEJ4TUGEJ1XUZNmmhQWUSSJdEJIdsWgohIIVFCQAlBRASUEICau4x0Y5qIJEmiLzut6T4EiNZCWLhwYewxiYjki1oIqMtIRASUEID6J4T77ruP++67L/7ARETyINEJIdNlp5nGEJ5//nmef/75+AMTEcmDRCcEdRmJiFRSQkAJQUQElBCA+k9uJyJSSHTZKdW3EKJMXdGiRYv4gxIRyZNEJ4RsZzv94x//GH9QIiJ5oi4jNIYgIgIJTwi1XXYapYVw5513cuedd8YfmIhIHiQ6IWTbQliwYAELFiyIPzARkTxQQqD+g8oiIoVECQFddioiAglPCGVlwQ9/UTV/hShjCCIihSTxl51W110EQUJwh127qk8YAB06dMhdcCIiDUwJoYaE0CT8y5SVQUlJ9XVmzpyZm8BERPIg8V1G1Y0fQNBCgMpxBhGRQpfohJCpywgq71WozoQJE5gwYUL8gYmI5IG6jDJ0GdXWQnjttdfiD0pEJE8S30LI1GVUWwtBRKSQREoIZnaqma0ws1VmdkM160vMbFq4/g0z6xaWdzCzF81ss5n9uso2C8N9Lg9fB8RxQnVRVpa5y0hjCCKSFBm7jMysGHgIOBkoBZaY2Wx3fy+t2mXARnc/1MwuAO4FRgLbgVuAI8NXVRe6+9Isz6Hesh1DEBEpJFFaCMcCq9z9Q3ffCTwFnFmlzpnA4+HnGcAwMzN33+LurxIkhn1OtmMIXbp0oUuXLvEHJiKSB1EGlTsDa9KWS4Hjaqrj7uVm9iXQAVifYd+PmVkFMBO4y909UtQxiXLZaW0thCeeeCL+oERE8iSfg8oXunsf4Jvh6+LqKpnZGDNbamZL161bF2sAUbqMNIYgIkkRJSGsBbqmLXcJy6qtY2ZNgLbAhtp26u5rw/dNwJMEXVPV1Zvk7gPcfUCnTp0ihBtdtmMI48ePZ/z48bHGJCKSL1G6jJYAPcysO8EP/wXAv1WpMxsYBbwGnAu8UFv3T5g09nf39WbWFDgdmF+P+LNS22Wn6VNX1GT58uXxByUikicZE0I4JnAlMBcoBia7+7tmdgew1N1nA48CU81sFfA5QdIAwMxWA/sBzczsLGA48A9gbpgMigmSwf/EemYR6LJTEZFKke5Udvc5wJwqZbemfd4OnFfDtt1q2O0x0ULMHV12KiJSKfF3Kmdz2amISCFJ9FxG2V522rNnz/iDEhHJk0QnhGwvO500aVL8QYmI5EniEkL6b/jmzbBixZ5lKRpDEJGkSfQYQkVF5Q9/VVHGEMaMGcOYMWPiD0xEJA8S10JIV1tCiNJC+Pvf/x5/UCIieZLYFsKuXcGrSQ0pUV1GIpI0iU0IFRXBe6aEoMtORSQpEpsQysuD92y6jERECklixxBSLYSaEkJRUfCqrYXQr1+/+AMTEcmTxCeEmrqMIEgWtbUQHnjggXiDEhHJI3UZ1dBCSK3TGIKIJEViE0KmLqPUutpaCBdddBEXXXRRvIGJiORJYruMUi2E2rqMmjSpvYVQWloab1AiInmU+BZCNmMIIiKFJLEJIcoYQqYWgohIIUlsQohjDEFEpJAkdgwhji6jQYMGxRuUiEgeJTYhxHHZ6U9/+tN4gxIRySN1GanLSEQESHBCiOOy03POOYdzzjkn3sBERPIksV1GcYwhbNiwId6gRETyKPEtBE1dISISSGxC0BiCiMieEp8QshlDEBEpJIkdQ4jaZVRbC2HYsGHxBiUikkeJTQhxdBndcsst8QYlIpJHie0yinLZqQaVRSRJEpsQorQQmjSpvYUwYsQIRowYEW9gIiJ5ktguo/Ly4JnJZjXXydRC2LZtW/yBiYjkSaJbCLV1F4EuOxWRZFFCqIXGEEQkSRKbEMrLax8/gGD9rl2V4w0iIoUssWMIFRWZE0KqBVFWVn3d008/Pf7ARETyJNEJIVOXUWr99u3QvPne66+77rr4AxMRyRN1GdWiRYvgfdOm3McjIpJvkRKCmZ1qZivMbJWZ3VDN+hIzmxauf8PMuoXlHczsRTPbbGa/rrLNMWb213CbX5nVdgFo/KIkhFSr4Kuvql8/dOhQhg4dGmtcIiL5kjEhmFkx8BAwAjgC+L6ZHVGl2mXARnc/FLgfuDcs3w7cAlTXt/IIcDnQI3ydWp8TqK8oXUaphKAWgogkQZQWwrHAKnf/0N13Ak8BZ1apcybwePh5BjDMzMzdt7j7qwSJYTczOxDYz91fd3cHfguclc2J1FWUQeVMLQQRkUISJSF0BtakLZeGZdXWcfdy4EugQ4Z9lmbYJwBmNsbMlprZ0nXr1kUIN5q6jCEoIYhIEuzzg8ruPsndB7j7gE6dOsW237p0GSkhiEgSRLnsdC3QNW25S1hWXZ1SM2sCtAVqe+Dw2nA/te0zpyoqKlsANcmUEM4///x4gxIRyaMoCWEJ0MPMuhP8aF8A/FuVOrOBUcBrwLnAC+HYQLXc/RMz+8rMjgfeAC4BHqxH/PVWl6uMahpUvuKKK+INSkQkjzImBHcvN7MrgblAMTDZ3d81szuApe4+G3gUmGpmq4DPCZIGAGa2GtgPaGZmZwHD3f094ApgCtAC+GP4ajBRBpWLi4NWRE0thK1btwLQsmXLmKMTEWl4ke5Udvc5wJwqZbemfd4OnFfDtt1qKF8KHBk10LhFGUMA2G+/mhPCaaedBsDChQvjC0xEJE/2+UHlXInSZQS1JwQRkUKihJCBEoKIJEViE0LULqM2bXSnsogkQ6ITgloIIiKVEjv9dRxdRqNHj441JhGRfEpsQojjKiMlBBEpJInsMtq1C9yzTwjr169n/fr18QYnIpIniWwhlJcH71G6jNq0CR6huWMHlJTsue7cc88FdB+CiBSGRLYQUgkhagsBNLAsIoUvkQmhrCx4b9o0c10lBBFJCiWEDJQQRCQplBAyUEIQkaRI5KByXRJCmzbBe3V3K//oRz+KLygRkTxLdELIdlB55MiR8QUlIpJniewySl1llG2X0Zo1a1izZs3eK0REGqFEtxCaNctct7aEcPHFFwO6D0FECkMiWwh16TJq2RKKijSoLCKFL9EJIUqXkVkwsKyEICKFTgkhgv320zMRRKTwJTIh1GVQGfRMBBFJhkQPKmebEK699tr4ghIRybNEJ4Qog8oQJISNG/cuP+OMM+ILSkQkzxLZZVTXhFDToPKKFStYsWJFfIGJiORRYlsITZsGVxBFUdOg8tixYwHdhyAihSGRLYTy8ujjB6BBZRFJhkQmhLKy6N1FUNlC2LUrdzGJiORboruMopg0Cd57L/j84IPQokXwecyY3MQmIpIviW0h1KXLKPUs5e3bcxOPiMi+QC2ECFKtgqoJ4eabb44vKBGRPEtsQqjLGELz5sF71YRw0kknxReUiEieJbbLKMrU1ympFsK2bXuWL1++nOXLl8cXmIhIHiWyhVBeXvmv/ihqaiGMHz8e0H0IIlIYEttCqE+XUdUWgohIIUlsQqjLoLISgogkgRJCBK1aBWMOn3+eu5hERPItkQmhrlNXmEHHjrBuXe5iEhHJt0g96WZ2KvBLoBj4jbv/rMr6EuC3wDHABmCku68O100ALgMqgKvdfW5YvhrYFJaXu/uAGM4nkrqOIQB06gSffbZn2T333BNfUCIieZbxZ9HMioGHgJOBUmCJmc129/fSql0GbHT3Q83sAuBeYKSZHQFcAPQGDgLmm1lPd68It/u2u6+P8XwiqWuXEcABBwRTWOzaBUVhu2rw4MHxBycikidRuoyOBVa5+4fuvhN4CjizSp0zgcfDzzOAYWZmYflT7r7D3T8CVoX7y5tdu6Ciou4JoVOnIJF8+WVl2aJFi1i0aFG8AYqI5EmUjpPOwJq05VLguJrquHu5mX0JdAjLX6+ybefwswPzzMyBie4+qbqDm9kYYAzAwQcfHCHc2tX1ecopnToF7+vWQbt2wecbb7wR0H0IIlIY8jmofKK7Hw2MAMaZ2beqq+Tuk9x9gLsP6JT6Vc5CXZ+nnJKeEEREClGUhLAW6Jq23CUsq7aOmTUB2hIMLte4rbun3j8DZtFAXUl1fXxmSvv2wdiBEoKIFKooCWEJ0MPMuptZM4JB4tlV6swGRoWfzwVecHcPyy8wsxIz6w70ABabWSszawNgZq2A4cA72Z9OZvVtIRQXQ4cOSggiUrgy/js5HBO4EphLcNnpZHd/18zuAJa6+2zgUWCqma0CPidIGoT1pgPvAeXAOHevMLOvAbOCcWeaAE+6+59ycH57qW9CgOovPRURKRSROk7cfQ4wp0rZrWmftwPn1bDt3cDdVco+BI6qa7BxyDYhrF5dufzAAw/EEpOIyL4gcbOdZpsQtm6FLVuC5X79+sUXmIhIniVu6opsEwJUjiPMnz+f+fPnxxOYiEieJa6FUN/7EKAyIaTGEe666y5AT04TkcKgFkId6F4EESlkiU0Idb0PAYIpsPffP2ghTJ8Of/sb7NwZb3wiIvmSuC6jbFoIEEyD/frrMHJkfDGJiOwLEttCqG9CGDAADjsM/vAH6NoV/vlP+POf44tPRCRfEtdCyGZQGeDb3w5eZ58N3bpNZMQIuPJKWLo0uJtZRKSxUguhniZNgiVLenHGGb1YvhwuuSQoExFprBKZEMwqH3KTjbfeeo5mzZ7j0ENhzpzKZCMi0hglMiE0bRokhWzNn/8L5s//Bf/6r/DFF/Daa9nvU0QkXxKbEOJ0+OHQrRvMnVs5RiEi0tgkLiGUl8efEMzgtNNg/Xr4/e/j3beISENJXEIoK6vfTWmZ9OkDnTvDPfeAe/z7FxHJtUQmhLhbCBAMUg8ZEty9vGpV/PsXEcm1xN2HEGdC+MEPpu6xfOihwftrr0GPHvEcQ0SkoaiFkIX27bvSvn3lI6MPPBDatAmmthARaWyUELKwZMk0liyZtnu5qAiOO06Xn4pI46SEkIWXX36El19+ZI+yQYPg7bcrn6omItJYJC4h5OKy03THHw+7dsGSJbk7hohILiQuIeTqstOU444L3jWOICKNTSITQi5bCB06QM+eGkcQkcZHCSEHBg0KWgi6QU1EGpPE3YcQ5xjC2LEz9iqbNClIOp99Fty1nHoO85gx8RxTRCRXEpcQ4hxDaN26Y7XlhxwSvK9cWZkQRET2dYnqMiovD64AiquFsGjRFBYtmrJXeefO8LWvwbx5UFERz7FERHItUQlh+/bgPa6E8NprU3jttSl7lRcVwVlnwSefaHBZRBoPJYQc6d8funeH556DnTtzfzwRkWwpIeSIGXzve8GT1F54IffHExHJViITQi5vTEvXsyccdRQ8/zwsXtwwxxQRqa9EJoRmzRrumBdfDPvtF4wprF3bcMcVEamrRF12GneX0VVXzclYp00bGDcO/uu/YMQIGDYMtm2Dk06Cc84JupZERPYFiUwIcXUZNWvWMlK9zp1h9Gh47LHg3oSiIpg4MehO+t//DdaLiORbIhNCXC2EhQsfBmDo0Csy1u3TJ2glQHAvxIIF8OyzcPDB0KtXcFXSv/87HHNMPLGJiNRVohLCtm3Be1wJYdmy6UC0hJCuqAhOPhn69QsuSX3rLZg7F6ZPh7vuguuug+LieGIUEYmq4BOCO9x3X3BPQGqyuYa47DSK1LQWnTvDkCHwu9/BDTfAz34G3/hGUH7ppXDGGUESERHJpUgJwcxOBX4JFAO/cfefVVlfAvwWOAbYAIx099XhugnAZUAFcLW7z42yz7iUlcEzz8CyZTBqVFC2rySEdK1aweWXB62Gd9+F9u3hzTeDq5MOPxwGDoTNm4OWQ58+wau4OHgyW8eOcMIJ0KJFvs9CRBqzjAnBzIqBh4CTgVJgiZnNdvf30qpdBmx090PN7ALgXmCkmR0BXAD0Bg4C5ptZz3CbTPuMRbNmMHs2DB4czEQKDXcfQl2ZwbHHBi+A008PEtmCBcHgc0nSgqu6AAAIVklEQVRJMB/TjBl7T61dUhIkjQ4doGXLPV8tWuy53KRJMI5RXByMYRxySFC2aVOw//btoV27IJlu2RKsa9s2qL99O3z+eXC8du2ClsvOnfDVV8EVVSUlDf93Eykk7vDee8H/923awPDhDXfhSZSfxmOBVe7+IYCZPQWcCaT/eJ8J3B5+ngH82swsLH/K3XcAH5nZqnB/RNhnbDp0gD/9KXi85Wef7ZsthOoUF++ZIFK2b4dPPw0+l5TAhg3w/vvw0UewenXwA53+Ki+PJ56SEtixY8/4Skpg69bKslatoHnzYFK/XbuC9/TPxcXQunVQb9u2IJGYBQmnVavKmIuKgn0XFQX1duwIknuLFsF+Nm0Kylq1CvZXURHUq6gItmvWLDjv1L6aNw/Kql7m6773q7ZyCPZRVBS8V/3sHpxr+na7dlVum143fduq9aset7pjpV6peKO8p0ttm+m9uvOpGldNf4vqzin9+LVtl75N1WPW9Pfftauybvpn98q6qfrpn9PrV32l1636qu6/p2xt2hT8TqXr3RtefDH3sydHSQidgTVpy6XAcTXVcfdyM/sS6BCWv15l21Suy7RPAMxsDJB6msBmM1sRIebqdATWA1x7bT33UIOxY/e5mwl2n2uc0pMBBD++6ckAghbFli0176OiImhhfP75nuVV/weIavt22LAhN+e7D0vS+SbpXKGG8333XTjggKz2+/UolfbRzpNK7j4JmJTtfsxsqbsPiCGkfV6SzhV0voUsSecK+T/fKNeurAW6pi13CcuqrWNmTYC2BIPLNW0bZZ8iItKAoiSEJUAPM+tuZs0IBolnV6kzGwiv4eFc4AV397D8AjMrMbPuQA9gccR9iohIA8rYZRSOCVwJzCW4RHSyu79rZncAS919NvAoMDUcNP6c4AeesN50gsHicmCcu1cAVLfP+E9vD1l3OzUiSTpX0PkWsiSdK+T5fM3jGBYXEZFGT/e/iogIoIQgIiKhgk8IZnaqma0ws1VmdkO+44mDmXU1sxfN7D0ze9fMrgnL25vZ/zOzleF7u7DczOxX4d/gbTM7Or9nUHdmVmxmb5rZ8+FydzN7IzynaeHFCYQXMEwLy98ws275jLs+zGx/M5thZn8zs/fNbFCBf7c/Dv87fsfMfm9mzQvl+zWzyWb2mZm9k1ZW5+/SzEaF9Vea2ajqjhWHgk4IadNujACOAL4fTqfR2JUD17r7EcDxwLjwvG4AFrh7D2BBuAzB+fcIX2OARxo+5KxdA7yftnwvcL+7HwpsJJg+BdKmUQHuD+s1Nr8E/uTuhwFHEZx3QX63ZtYZuBoY4O5HElxkkpr+phC+3ynAqVXK6vRdmll74DaCm3ePBW5LJZHYuXvBvoBBwNy05QnAhHzHlYPzfJZgXqgVwIFh2YHAivDzROD7afV312sML4L7VBYA3wGeB4zgbs4mVb9ngivXBoWfm4T1LN/nUIdzbQt8VDXmAv5uU7MctA+/r+eBUwrp+wW6Ae/U97sEvg9MTCvfo16cr4JuIVD9tBsF9XyysMncH3gD+Jq7fxKu+hT4Wvi5sf8dHgCuB1KzAnUAvnD31CxN6eezxzQqQGoalcaiO7AOeCzsIvuNmbWiQL9bd18L3Ad8DHxC8H0to3C/X6j7d9lg33GhJ4SCZmatgZnAeHf/Kn2dB/+UaPTXFJvZ6cBn7r4s37E0kCbA0cAj7t4f2EJllwJQON8tQNj1cSZBIjwIaMXeXSwFa1/7Lgs9IRTsFBlm1pQgGfzO3f8QFv/TzA4M1x8IpKaMa8x/hxOA75rZauApgm6jXwL7h9OkwJ7nU9M0Ko1FKVDq7m+EyzMIEkQhfrcAJwEfufs6dy8D/kDwnRfq9wt1/y4b7Dsu9IRQkFNkmJkR3B3+vrv/V9qq9ClERhGMLaTKLwmvYjge+DKtybpPc/cJ7t7F3bsRfH8vuPuFwIsE06TA3uda3TQqjYK7fwqsMbNeYdEwgjv9C+67DX0MHG9mLcP/rlPnW5Dfb6iu3+VcYLiZtQtbVMPDsvjle8ClAQZ0TgP+DnwA3JTveGI6pxMJmplvA8vD12kEfakLgJXAfKB9WN8Irrb6APgrwRUdeT+Pepz3UOD58PMhBPNirQKeBkrC8ubh8qpw/SH5jrse59kPWBp+v88A7Qr5uwV+AvwNeAeYCpQUyvcL/J5gbKSMoPV3WX2+S+DS8JxXAT/IVbyaukJERIDC7zISEZGIlBBERARQQhARkZASgoiIAEoIIiISUkIQERFACUFkNzO73cyui2E/3dKnOxZpLJQQREQEUEKQhDOzm8zs72b2KtArLOtnZq+HDymZlfYAk0PNbL6ZvWVmfzGzb0TYf7GZ/dzMloT7GxuWDzWzhWkPwvldOHWDSN4oIUhimdkxBPMj9SOY+mNguOq3wH+4e1+CKQRuC8t/Bzzk7kcBgwmmJMjkMoI5aQaG+7/czLqH6/oD4wke3nQIwaRuInnTJHMVkYL1TWCWu28FMLPZBNMv7+/uL4V1HgeeNrM2QGd3nwXg7tsjHmM40NfMUhO1tSV4ItZOYLG7l4bHXk7wIJVXsz4rkXpSQhDJLQOucvc9Zqc0s6HAjrSiCvT/o+SZuowkyV4GzjKzFmEL4AyCB9JsNLNvhnUuBl5y901AqZmdBbsf9t4ywjHmAj8Kn1+BmfUMn4Amss/Rv0gksdz9L2Y2DXiL4CElS8JVo4D/Dn/wPwR+EJZfDEw0szsIpjM+L1xfm98QdAX9JRw0XgecFed5iMRF01+LiAigLiMREQmpy0iknsysD8ETvtLtcPfj8hGPSLbUZSQiIoC6jEREJKSEICIigBKCiIiElBBERASA/w8feEkbQf/LuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train['doc_len'] = train[\"tweet\"].apply(lambda words: len(words.split(\" \")))\n",
    "max_seq_len = np.round(train['doc_len'].mean() + train['doc_len'].std()).astype(int)\n",
    "sns.distplot(train['doc_len'], hist=True, kde=True, color='b', label='doc len')\n",
    "plt.axvline(x=max_seq_len, color='k', linestyle='--', label='max len')\n",
    "plt.title('tweet length'); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape :  (30954, 5)\n"
     ]
    }
   ],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = None # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = max_seq_len # max number of words in a question to use #99.99%\n",
    "\n",
    "## fill up the missing values\n",
    "X = train[\"tweet\"].fillna(\"_na_\").values\n",
    "print(\"Test shape : \", test.shape)\n",
    "X_test = test[\"tweet\"].fillna(\"_na_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "tokenizer.fit_on_texts(list(X))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "## Pad the sentences \n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "Y = train['gender'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    63166\n",
       "male      60648\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(Y)\n",
    "encoded_Y = le.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "max_features = len(word_index)+1\n",
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '/data/glove/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if o.split(\" \")[0] in word_index)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix \n",
    "    \n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = '/data/fasttext/crawl-300d-2M-subword.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100 and o.split(\" \")[0] in word_index )\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Glove vectors have been used in embedding matrix. Can explore it further in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = load_fasttext(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definning the Capsule Layer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "            \n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule, self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capsule Layer with a Bi directional GRU. Architecture found in text classification project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capsule():\n",
    "    K.clear_session()       \n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = SpatialDropout1D(rate=0.2)(x)\n",
    "    x = Bidirectional(GRU(100, return_sequences=True, \n",
    "                                kernel_initializer=glorot_normal(seed=12300), recurrent_initializer=orthogonal(gain=1.0, seed=10000)))(x)\n",
    "\n",
    "    x = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(100, activation=\"relu\", kernel_initializer=glorot_normal(seed=12300))(x)\n",
    "    x = Dropout(0.12)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(),)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_smart(y_true, y_pred):\n",
    "    args = np.argsort(y_pred)\n",
    "    tp = y_true.sum()\n",
    "    fs = (tp - np.cumsum(y_true[args[:-1]])) / np.arange(y_true.shape[0] + tp - 1, tp, -1)\n",
    "    res_idx = np.argmax(fs)\n",
    "    return 2 * fs[res_idx], (y_pred[args[res_idx]] + y_pred[args[res_idx + 1]]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with early stopping and reducing learning rate on plateu. In each fold values for the test set is also predicted, And after the process, predicted values for the test file would be mean from each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 76)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 76, 300)           63901500  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 76, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 76, 200)           240600    \n",
      "_________________________________________________________________\n",
      "capsule_1 (Capsule)          (None, 10, 10)            20000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 64,172,701\n",
      "Trainable params: 271,001\n",
      "Non-trainable params: 63,901,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 99050 samples, validate on 24764 samples\n",
      "Epoch 1/20\n",
      " - 99s - loss: 0.6512 - val_loss: 0.6114\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61142, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 100s - loss: 0.6020 - val_loss: 0.5782\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61142 to 0.57815, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 99s - loss: 0.5783 - val_loss: 0.5627\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57815 to 0.56270, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/20\n",
      " - 99s - loss: 0.5554 - val_loss: 0.5506\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56270 to 0.55062, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/20\n",
      " - 100s - loss: 0.5329 - val_loss: 0.5305\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55062 to 0.53054, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/20\n",
      " - 100s - loss: 0.5149 - val_loss: 0.5216\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.53054 to 0.52160, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 7/20\n",
      " - 99s - loss: 0.4962 - val_loss: 0.5161\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52160 to 0.51606, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 8/20\n",
      " - 99s - loss: 0.4747 - val_loss: 0.5033\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51606 to 0.50334, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 9/20\n",
      " - 99s - loss: 0.4569 - val_loss: 0.4973\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50334 to 0.49735, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 10/20\n",
      " - 98s - loss: 0.4412 - val_loss: 0.4964\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49735 to 0.49638, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 11/20\n",
      " - 99s - loss: 0.4250 - val_loss: 0.5317\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.49638\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 12/20\n",
      " - 99s - loss: 0.3947 - val_loss: 0.4947\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.49638 to 0.49469, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 13/20\n",
      " - 99s - loss: 0.3810 - val_loss: 0.5071\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 14/20\n",
      " - 99s - loss: 0.3595 - val_loss: 0.5204\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 15/20\n",
      " - 99s - loss: 0.3459 - val_loss: 0.5079\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 16/20\n",
      " - 99s - loss: 0.3352 - val_loss: 0.5146\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.49469\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 17/20\n",
      " - 100s - loss: 0.3300 - val_loss: 0.5314\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.49469\n",
      "Epoch 18/20\n",
      " - 99s - loss: 0.3280 - val_loss: 0.5296\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.49469\n",
      "Epoch 19/20\n",
      " - 99s - loss: 0.3264 - val_loss: 0.5212\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.49469\n",
      "Epoch 20/20\n",
      " - 99s - loss: 0.3208 - val_loss: 0.5261\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.49469\n",
      "Optimal F1: 0.7589 at threshold: 0.3361\n",
      "Train on 99051 samples, validate on 24763 samples\n",
      "Epoch 1/20\n",
      " - 100s - loss: 0.6552 - val_loss: 0.6151\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61511, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 99s - loss: 0.6043 - val_loss: 0.5908\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61511 to 0.59080, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 99s - loss: 0.5890 - val_loss: 0.6546\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59080\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 4/20\n",
      " - 99s - loss: 0.5682 - val_loss: 0.5743\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59080 to 0.57425, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/20\n",
      " - 99s - loss: 0.5525 - val_loss: 0.5474\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57425 to 0.54741, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/20\n",
      " - 99s - loss: 0.5400 - val_loss: 0.5431\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54741 to 0.54312, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 7/20\n",
      " - 99s - loss: 0.5266 - val_loss: 0.5313\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.54312 to 0.53126, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 8/20\n",
      " - 99s - loss: 0.5156 - val_loss: 0.5261\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.53126 to 0.52609, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 9/20\n",
      " - 99s - loss: 0.5043 - val_loss: 0.5266\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.52609\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 10/20\n",
      " - 99s - loss: 0.4845 - val_loss: 0.5117\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52609 to 0.51173, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 11/20\n",
      " - 99s - loss: 0.4754 - val_loss: 0.5118\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.51173\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 12/20\n",
      " - 101s - loss: 0.4616 - val_loss: 0.5078\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.51173 to 0.50784, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 13/20\n",
      " - 101s - loss: 0.4555 - val_loss: 0.5108\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.50784\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 14/20\n",
      " - 102s - loss: 0.4460 - val_loss: 0.5059\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.50784 to 0.50586, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 15/20\n",
      " - 103s - loss: 0.4410 - val_loss: 0.5116\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.50586\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 16/20\n",
      " - 101s - loss: 0.4373 - val_loss: 0.5037\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.50586 to 0.50365, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 17/20\n",
      " - 103s - loss: 0.4330 - val_loss: 0.5078\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.50365\n",
      "Epoch 18/20\n",
      " - 102s - loss: 0.4298 - val_loss: 0.5039\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.50365\n",
      "Epoch 19/20\n",
      " - 101s - loss: 0.4285 - val_loss: 0.5114\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.50365\n",
      "Epoch 20/20\n",
      " - 102s - loss: 0.4263 - val_loss: 0.5055\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50365\n",
      "Optimal F1: 0.7548 at threshold: 0.3935\n",
      "Train on 99051 samples, validate on 24763 samples\n",
      "Epoch 1/20\n",
      " - 102s - loss: 0.6554 - val_loss: 0.6015\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60149, saving model to models/capsule_net_weights_best.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      " - 101s - loss: 0.6054 - val_loss: 0.5819\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60149 to 0.58188, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 100s - loss: 0.5813 - val_loss: 0.5640\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58188 to 0.56400, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/20\n",
      " - 100s - loss: 0.5593 - val_loss: 0.5399\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56400 to 0.53991, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/20\n",
      " - 100s - loss: 0.5389 - val_loss: 0.5300\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53991 to 0.52997, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/20\n",
      " - 99s - loss: 0.5176 - val_loss: 0.5331\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52997\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 7/20\n",
      " - 100s - loss: 0.4930 - val_loss: 0.5034\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52997 to 0.50335, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 8/20\n",
      " - 102s - loss: 0.4773 - val_loss: 0.5084\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.50335\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 9/20\n",
      " - 101s - loss: 0.4577 - val_loss: 0.4945\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50335 to 0.49445, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 10/20\n",
      " - 101s - loss: 0.4473 - val_loss: 0.4950\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.49445\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 11/20\n",
      " - 101s - loss: 0.4355 - val_loss: 0.4890\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.49445 to 0.48899, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 12/20\n",
      " - 100s - loss: 0.4287 - val_loss: 0.4914\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48899\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 13/20\n",
      " - 100s - loss: 0.4190 - val_loss: 0.4938\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48899\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 14/20\n",
      " - 99s - loss: 0.4126 - val_loss: 0.4936\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48899\n",
      "Epoch 15/20\n",
      " - 99s - loss: 0.4116 - val_loss: 0.4921\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48899\n",
      "Epoch 16/20\n",
      " - 100s - loss: 0.4074 - val_loss: 0.4961\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.48899\n",
      "Epoch 17/20\n",
      " - 100s - loss: 0.4035 - val_loss: 0.4952\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.48899\n",
      "Epoch 18/20\n",
      " - 100s - loss: 0.4019 - val_loss: 0.4981\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.48899\n",
      "Epoch 19/20\n",
      " - 101s - loss: 0.3978 - val_loss: 0.4970\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.48899\n",
      "Epoch 20/20\n",
      " - 99s - loss: 0.3964 - val_loss: 0.4991\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.48899\n",
      "Optimal F1: 0.7589 at threshold: 0.3434\n",
      "Train on 99052 samples, validate on 24762 samples\n",
      "Epoch 1/20\n",
      " - 98s - loss: 0.6562 - val_loss: 0.6085\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60846, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 104s - loss: 0.6067 - val_loss: 0.5811\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60846 to 0.58111, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 101s - loss: 0.5841 - val_loss: 0.5692\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58111 to 0.56916, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/20\n",
      " - 99s - loss: 0.5609 - val_loss: 0.5415\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56916 to 0.54148, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/20\n",
      " - 100s - loss: 0.5385 - val_loss: 0.5318\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54148 to 0.53181, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/20\n",
      " - 101s - loss: 0.5169 - val_loss: 0.5160\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.53181 to 0.51600, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 7/20\n",
      " - 100s - loss: 0.4959 - val_loss: 0.5114\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.51600 to 0.51144, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 8/20\n",
      " - 100s - loss: 0.4795 - val_loss: 0.5394\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51144\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 9/20\n",
      " - 100s - loss: 0.4542 - val_loss: 0.4939\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51144 to 0.49391, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 10/20\n",
      " - 101s - loss: 0.4385 - val_loss: 0.4879\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49391 to 0.48793, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 11/20\n",
      " - 101s - loss: 0.4252 - val_loss: 0.4912\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 12/20\n",
      " - 101s - loss: 0.4051 - val_loss: 0.4927\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 13/20\n",
      " - 104s - loss: 0.3893 - val_loss: 0.4945\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 14/20\n",
      " - 102s - loss: 0.3793 - val_loss: 0.4965\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 15/20\n",
      " - 103s - loss: 0.3753 - val_loss: 0.4958\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48793\n",
      "Epoch 16/20\n",
      " - 99s - loss: 0.3717 - val_loss: 0.4963\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.48793\n",
      "Epoch 17/20\n",
      " - 99s - loss: 0.3694 - val_loss: 0.5000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.48793\n",
      "Epoch 18/20\n",
      " - 98s - loss: 0.3651 - val_loss: 0.4980\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.48793\n",
      "Epoch 19/20\n",
      " - 98s - loss: 0.3635 - val_loss: 0.4939\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.48793\n",
      "Epoch 20/20\n",
      " - 100s - loss: 0.3609 - val_loss: 0.4992\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.48793\n",
      "Optimal F1: 0.7607 at threshold: 0.3458\n",
      "Train on 99052 samples, validate on 24762 samples\n",
      "Epoch 1/20\n",
      " - 104s - loss: 0.6561 - val_loss: 0.6498\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64979, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/20\n",
      " - 101s - loss: 0.6002 - val_loss: 0.5831\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64979 to 0.58308, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/20\n",
      " - 100s - loss: 0.5795 - val_loss: 0.5767\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58308 to 0.57667, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/20\n",
      " - 98s - loss: 0.5579 - val_loss: 0.5549\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57667 to 0.55486, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/20\n",
      " - 100s - loss: 0.5389 - val_loss: 0.5451\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55486 to 0.54509, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/20\n",
      " - 100s - loss: 0.5221 - val_loss: 0.5281\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54509 to 0.52812, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 7/20\n",
      " - 99s - loss: 0.5056 - val_loss: 0.5443\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.52812\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 8/20\n",
      " - 99s - loss: 0.4836 - val_loss: 0.5096\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.52812 to 0.50957, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 9/20\n",
      " - 100s - loss: 0.4680 - val_loss: 0.5100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.50957\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 10/20\n",
      " - 100s - loss: 0.4542 - val_loss: 0.5085\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.50957 to 0.50849, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 11/20\n",
      " - 100s - loss: 0.4462 - val_loss: 0.5087\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.50849\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 12/20\n",
      " - 100s - loss: 0.4351 - val_loss: 0.5111\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.50849\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 13/20\n",
      " - 100s - loss: 0.4286 - val_loss: 0.5038\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.50849 to 0.50376, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 14/20\n",
      " - 99s - loss: 0.4249 - val_loss: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss did not improve from 0.50376\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 15/20\n",
      " - 101s - loss: 0.4217 - val_loss: 0.5130\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.50376\n",
      "Epoch 16/20\n",
      " - 100s - loss: 0.4178 - val_loss: 0.5086\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.50376\n",
      "Epoch 17/20\n",
      " - 100s - loss: 0.4171 - val_loss: 0.5115\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.50376\n",
      "Epoch 18/20\n",
      " - 99s - loss: 0.4150 - val_loss: 0.5071\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.50376\n",
      "Epoch 19/20\n",
      " - 100s - loss: 0.4105 - val_loss: 0.5057\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.50376\n",
      "Epoch 20/20\n",
      " - 101s - loss: 0.4095 - val_loss: 0.5043\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50376\n",
      "Optimal F1: 0.7578 at threshold: 0.3774\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=10, shuffle=True)\n",
    "bestscore = []\n",
    "y_test = np.zeros((X_test.shape[0], ))\n",
    "for i, (train_index, valid_index) in enumerate(kfold.split(X, encoded_Y)):\n",
    "    X_train, X_val, Y_train, Y_val = X[train_index], X[valid_index], encoded_Y[train_index], encoded_Y[valid_index]\n",
    "    filepath=\"models/capsule_net_weights_best.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=1, min_lr=0.0001, verbose=2)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=2, mode='auto')\n",
    "    callbacks = [checkpoint, reduce_lr]\n",
    "    model = capsule()\n",
    "    if i == 0:print(model.summary()) \n",
    "    model.fit(X_train, Y_train, batch_size=64, epochs=20, validation_data=(X_val, Y_val), verbose=2, callbacks=callbacks, \n",
    "             )\n",
    "    model.load_weights(filepath)\n",
    "    y_pred = model.predict([X_val], batch_size=64, verbose=2)\n",
    "    y_test += np.squeeze(model.predict([X_test], batch_size=64, verbose=2))/5\n",
    "    f1, threshold = f1_smart(np.squeeze(Y_val), np.squeeze(y_pred))\n",
    "    print('Optimal F1: {:.4f} at threshold: {:.4f}'.format(f1, threshold))\n",
    "    bestscore.append(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the predictions for integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py:273: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.reshape((-1, 1))\n",
    "pred_test_y = (y_test>np.mean(bestscore)).astype(int)\n",
    "test['predictions'] = le.inverse_transform(pred_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9001, 6742, 1381, 13830)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(test[\"gender\"], test['predictions']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714253408283259"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test[\"gender\"], test['predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sentence_similarity_3.6]",
   "language": "python",
   "name": "conda-env-sentence_similarity_3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
